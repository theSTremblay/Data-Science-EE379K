{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Put your NAME and EID here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Set 01b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this first assignment, we want you to get familiar with jupyter notebooks as well as common Python packages that will be used in this class. If you need any help, refer to the documentation hints for the problems.\n",
    "\n",
    "Make sure you have the following packages installed for Python3:\n",
    "\n",
    "- numpy\n",
    "- matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports needed\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sio\n",
    "\n",
    "# setting seed, DON'T modify\n",
    "np.random.seed(10)\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 10, 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no need to modify this\n",
    "def poly_feature(X,poly = 1):\n",
    "    # expects an array (X) of shape (n,1)\n",
    "    newX = []\n",
    "    for i in range(poly+1):\n",
    "        newX.append(X**i)\n",
    "    return np.concatenate(newX, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1: Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this problem, we will be exploring a simple linear regression example. The data can be found in **ps01.data**.\n",
    "\n",
    "### Part A.\n",
    "\n",
    "We want you to:\n",
    "\n",
    "- First load in the dataset (**ps01.data**) using numpy. \n",
    "\n",
    "    - The structure will be a little different than last homework. After using **np.load**, call **.item()** on the object.\n",
    "    - If done correctly, you should see a dictionary containing the keys **(\"Xtrain,\"Xtest\",\"Ytrain\",\"Ytest\")**.\n",
    "    \n",
    "    \n",
    "- Plot both the train and test data (on the same plot), each with a different color. Make sure to include a legend.\n",
    "\n",
    "\n",
    "Useful modules:\n",
    "    - np.load\n",
    "    - plt.scatter, plt.legend\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part B.\n",
    "\n",
    "We can notice a positive correlation from the previous plot. Thus, let's try to learn a simple linear regression model:\n",
    "\n",
    "$$y^{(i)} \\approx \\hat{y}^{(i)} = \\beta_0 + \\beta_1 x^{(i)}$$\n",
    "\n",
    "Recall the objective to find the optimal $\\beta$:\n",
    "\n",
    "$$ \\min_\\beta \\sum_i ||y - X\\beta||^2 $$\n",
    "\n",
    "We want you to now:\n",
    "\n",
    "- Solve for $\\beta$ ONLY using **Xtrain** and **Ytrain**. \n",
    "    - Make sure to use the right formula. (Does n>d or n<d?)\n",
    "    - Don't forget to include the extra \"1\" term in your features to include $\\beta_0$. \n",
    "    - We have included a function you may use to do this.\n",
    "    \n",
    "- Overlay the line with the original data points in a **new plot**.\n",
    "    - You will want to create a **continuous line** (rather than scatterplot) for the linear regression model.\n",
    "    - Make sure to include the **test data** in the scatter plot as well.\n",
    "    - Include a legend labeling each part of the plot.\n",
    "    \n",
    "- Does this model fit the test data well? Calculate the **test set error** using the following formula:\n",
    "\n",
    "$$ E = \\frac{1}{n}\\sum_{i=1}^n || y^{(i)} - \\hat{y}^{(i)} || ^ 2 $$\n",
    "\n",
    "- Also calculate **both** the **train** and **test** $R^2$ statistic:\n",
    "\n",
    "$$ R^2 = 1 - \\frac{\\sum_{i=1}^n ( y^{(i)} - \\hat{y}^{(i)} ) ^ 2}{\\sum_{i=1}^n (y^{(i)}-\\bar{y}) ^ 2} $$\n",
    "\n",
    "Useful modules:\n",
    "    - poly_feature\n",
    "    - np.linalg.inv\n",
    "    - np.transpose\n",
    "    - np.linspace\n",
    "    - np.mean\n",
    "    - plt.scatter\n",
    "    - plt.legend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part C.\n",
    "\n",
    "We clearly need a more complex model -- luckily, we can still use linear regression, i.e. only solve for a new $\\beta$.\n",
    "\n",
    "One way to do this is to use non-linear features in our model. One such example is to also include a quadratic term.\n",
    "\n",
    "$$y^{(i)} \\approx \\hat{y}^{(i)} = \\beta_0 + \\beta_1 x^{(i)} + \\beta_2 ({x^{(i)}})^2$$\n",
    "\n",
    "This can still be solved using least squares, since $\\beta$ is still linear w.r.t. our quadratic term. We can further extend this to any power $d$: \n",
    "\n",
    "$$\\hat{y}^{(i)} = \\beta_0 + \\beta_1 x^{(i)} +\\ ...\\ + \\beta_d (x^{(i)})^d$$\n",
    "\n",
    "Thus, in this part, we want you to:\n",
    "\n",
    "- Solve for $\\beta$ using $d = [2,3,4,5,6,7]$.\n",
    "\n",
    "    - Similar to the previous, you can make use of **poly_feature** to generate the features.\n",
    "\n",
    "- Overlay each new model (each polynomial of degree **d** with coefficients $\\beta$) over the train and test data.\n",
    "    \n",
    "    - There should only be **one figure**. It will be similar to part B but with 9 continuous lines (rather than 1).\n",
    "    - Make sure to **label each** in a legend.\n",
    "    - We suggest setting a **limit** on the y-axis to stay within [-20,20].\n",
    "\n",
    "- Calculate **test errors** $E_d$ for each d. Plot out an E vs. d plot.\n",
    "\n",
    "- Calculate **train** and **test** $R^2$ for each d. \n",
    "    - Using **only 1** figure, graph **BOTH** the **train** and **test** R2 vs $d$.\n",
    "    - This should contain **two** solid lines that are labeled with a color. Please include a legend denoting train/test.\n",
    "\n",
    "- Using these plots, what value of $d$ do you think the data came from? \n",
    "    \n",
    "\n",
    "Useful modules:\n",
    "    - poly_feature\n",
    "    - np.linalg.inv\n",
    "    - np.transpose\n",
    "    - np.linspace\n",
    "    - np.mean\n",
    "    - plt.scatter\n",
    "    - plt.legend\n",
    "    - plt.ylim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turn in Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have completed Problems 1 and 2, please submit (for this part of the assignment):\n",
    "\n",
    "- This .ipynb file.\n",
    "- A PDF version of this file. To do this:\n",
    "    1. Go to File -> Download as -> HTML\n",
    "    2. Open the HTML and Print, and change the **destination** to **PDF**."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
