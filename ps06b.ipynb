{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Put your NAME and EID here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Set 06b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure you have the following packages installed for Python3:\n",
    "\n",
    "- scikit-learn\n",
    "- numpy\n",
    "- matplotlib\n",
    "- scipy\n",
    "- skimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports needed\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.ndimage\n",
    "import scipy.io\n",
    "from skimage import io\n",
    "\n",
    "# setting seed, DON'T modify\n",
    "np.random.seed(10)\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 10, 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1: Image Segmentation using K-means Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this homework, you will be applying K-means clustering to obtain segmentations of images. This is based off of an assignment of CS 376: Computer Vision taught by Dr. Kristen Grauman. You can view the course [here](http://vision.cs.utexas.edu/376-spring2018/) as well as the original assignment [here](http://vision.cs.utexas.edu/376-spring2018/assignments/a2/A2-spring2018.pdf).\n",
    "\n",
    "Because this course does not cover topics such as image filtering and textures, we will provide starter code that already does this for you using Python libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part A.\n",
    "\n",
    "To be able to complete this homework, you will need be able to load in some assets (provided in the .zip). Please do the following:\n",
    "\n",
    "- Complete the **loadImages** function to load in a set of images given filenames.\n",
    "    - This will contain an option to load in grayscale versions as well.\n",
    "    - Make sure to normalize the color images. ([0,255] -> [0,1])\n",
    "    \n",
    "- In addition, use the **loadFilterBank** function to load in the image filters to be used in the assignment. Please visualize all filters using a **5 by 8 subplot**.\n",
    "    - The dimensions of the filter bank will be **49 x 49 x 38**.\n",
    "    \n",
    "- Now familiarize yourself with the **getFilterResponses** function that extracts **pixel features** based off of image [convolutions](https://en.wikipedia.org/wiki/Digital_image_processing).\n",
    "    - The filters extracted from the previous step will be used in this function. They are essentially ways to extract information from neighboring pixels across the image.\n",
    "    - The output will be **n x d**, where $n$ is the number of pixels extracted and $d$ will correspond to the number of filters in the given filter bank.\n",
    "    - These features will be used in the next part to segment using kmeans.\n",
    "    \n",
    "    \n",
    "Useful modules:\n",
    "    - skimage.io.imread\n",
    "    - plt.subplot\n",
    "    - np.reshape\n",
    "    - np.random.choice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadImages(files = ['gumballs.jpg','snake.jpg','twins.jpg'], grayscale = False):\n",
    "    images = []\n",
    "    for filename in files:\n",
    "        # load in image, using grayscale parameter\n",
    "        x = \n",
    "        if not grayscale:\n",
    "            # make sure to scale to [0,1] if color image\n",
    "            x = \n",
    "        images.append(x)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadFilterBank():\n",
    "    return scipy.io.loadmat('filterBank.mat')['F']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Inputs:\n",
    "    - imageStack : list of numpy arrays of dimension N x M x 3 (where N and M can differ between each image)\n",
    "    - F          : filter bank of dimension 49 x 49 x d where d = # of filters\n",
    "    - subsample  : subsampling rate to only return a percentage of pixel features\n",
    "Outputs:\n",
    "    - features   : 2D numpy array containing the filter responses of imageStack using F\n",
    "'''\n",
    "def getFilterResponses(imageStack, F, subsample=0.05):\n",
    "    features = []\n",
    "    for image in imageStack:\n",
    "        N, M, d = image.shape[0], image.shape[1], F.shape[2]\n",
    "        responses = np.zeros((N,M,d))\n",
    "        for i in range(d):\n",
    "            filter = F[:,:,i]\n",
    "            responses[:,:,i] = scipy.ndimage.convolve(image,filter)\n",
    "            \n",
    "        responses = responses.reshape(N*M, d)\n",
    "        sample_idx = np.random.choice(N*M, int(N*M*subsample), replace=False)\n",
    "        sampled_responses = responses[sample_idx,:]\n",
    "        features.append(sampled_responses)\n",
    "    features = np.concatenate(features, axis=0)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part B.\n",
    "\n",
    "In this section, we will be using k-means to compute texture features. The features themselves will be histograms of **quantized** filter responses of a neighborhood around a pixel. We will walk you through this process with the following steps:\n",
    "\n",
    "- First complete the **createTextons** function. \n",
    "    - This function will take an array of gathered **filterResponses** as input.\n",
    "    - Now, using the KMeans module from scikit-learn, fit it on filterResponses.\n",
    "    - This will return a trained KMeans (**textons**) to be used in the next function.\n",
    "    \n",
    "- Now, complete the **getTextonFeatures** function.\n",
    "    - Most of it has been completed, but it still needs to be filled in by using the previous function.\n",
    "    - It should take as input a **trained** KMeans module (**textons**) from calling createTextons in another cell. \n",
    "    - (1) The function will first convolve the input filter bank on an input image. (This is done for you)\n",
    "        - The result of this will be an **N x M x d** array of responses.\n",
    "    - (2) Next, create another array of size **N x M** of quantized filter responses for each pixel. To do this:\n",
    "        - We could naively loop through each pixel, but this can be quickly vectorized by doing the following.\n",
    "        - First, reshape the array from (1) into an array of **NM x d** array. \n",
    "        - Next, pass this into the kmeans module to compute their quantized filter responses (i.e. nearest texton). This should be a 1D numpy array containing the new labels. We are essentially mapping the filter responses into a discrete amount of vectors for (3).\n",
    "        - Finally, reshape the labels back into dimension **N x M**.\n",
    "    - (3) Next, we will create **histogram features** of each pixel using their neighborhood's quantized results. Initialize a new array of size **N x M x k**. For each pixel do the following:\n",
    "        - Using the window_size input, look at surrounding pixels (in a box). (This is already completed with inner for loops).\n",
    "        - Now collect the neighborhood's corresponding quantized labels from step (2). Specifically, collect the number of each quantized label in the neighborhood.\n",
    "            - We have setup an array of size $k$ for this -- just increment each index based on the neighborhood.\n",
    "        - Now store this result in the histogram array.\n",
    "        - **Note:** This can also be vectorized (i.e. without the two inner for loops) but be sure to use correct bounds.\n",
    "        \n",
    "        \n",
    "     - Now just return the array from (3).\n",
    "    \n",
    "Useful modules:\n",
    "    - sklearn.cluster.KMeans (.predict)\n",
    "    - np.reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Inputs:\n",
    "    - filterResponses : 2D numpy array containing a set of filter responses from pixels. \n",
    "                            - Each row should contain d filter responses where d = size of filter bank used\n",
    "    - numTextons      : int, specifying the number of cluster centers to find from filterResponses\n",
    "Outputs:\n",
    "    - textons         : scikit-learn KMeans module that has been fitted on filterResponses\n",
    "'''\n",
    "def createTextons(filterResponses, numTextons=50):\n",
    "    textons = # Create KMeans module\n",
    "    # Now fit on filterResponses \n",
    "    \n",
    "    return textons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Inputs:\n",
    "    - image        : grayscale image as a numpy array of size N x M\n",
    "    - textons      : an sklearn.cluster.KMeans module that has been trained on filterResponses\n",
    "    - F            : filter bank of dimension 49 x 49 x d where d = # of filters\n",
    "    - window_size  : dimension of square window centered at current pixel to collect histogram information\n",
    "Outputs:\n",
    "    - features   : 2D numpy array containing the filter responses of imageStack using F\n",
    "'''\n",
    "def getTextonFeatures(image, textons, F, window_size = 7):\n",
    "    N, M, d = image.shape[0], image.shape[1], F.shape[2]\n",
    "    k = textons.n_clusters\n",
    "    \n",
    "    print(\"Step 1...\")\n",
    "    # Step (1)\n",
    "    responses = np.zeros((N,M,d))\n",
    "    for i in range(d):\n",
    "        filter = F[:,:,i]\n",
    "        responses[:,:,i] = scipy.ndimage.convolve(image,filter)\n",
    "    \n",
    "    print(\"Step 2...\")\n",
    "    # Step (2)\n",
    "    # add in as much code to obtain a final quantized_responses array\n",
    "    quantized_responses = \n",
    "    \n",
    "    print(\"Step 3...\")\n",
    "    # Step (3)\n",
    "    histograms = np.zeros((N,M,k))\n",
    "    for i in range(N):\n",
    "        for j in range(M):\n",
    "            # current histogram should have k entries where:\n",
    "            #    i-th element will contain the # of times a quantized centroid occurs\n",
    "            hist = np.array([0 for i in range(k)])\n",
    "            \n",
    "            # go through the neighborhood\n",
    "            for x in range( max(0, i - window_size // 2), min(N, i + window_size // 2 + 1) ):\n",
    "                for y in range( max(0, j - window_size // 2), min(M, j + window_size // 2 + 1) ):\n",
    "                    current_quantized = # collect the neighborhood stats\n",
    "                    # don't forget to update hist\n",
    "                    \n",
    "            # set the pixel's completed histogram\n",
    "            histograms[i,j] = hist\n",
    "    \n",
    "    return histograms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part C.\n",
    "\n",
    "Once the previous two functions have been written, we can now compute the image segmentations. This will be done by another K-means clustering. Please do the following:\n",
    "\n",
    "- Complete the createSegmentation function.\n",
    "    - The input will be **N x M x d** array of features. \n",
    "    - Run K-means on this (make sure to first reshape to **NM x d**) using the given k.\n",
    "    - Now provide the correct label for each feature.\n",
    "    - **Note:** this is pretty similar to step (2) of getTextonFeatures, except you must train another kmeans module.\n",
    "\n",
    "Useful modules:\n",
    "    - sklearn.cluster.KMeans\n",
    "    - np.reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Inputs:\n",
    "    - features     : 3D numpy array containing a set of features for each pixel in an image\n",
    "    - k            : int, specifying the number of image segments desired\n",
    "Outputs:\n",
    "    - segmentation : 2D numpy array containing a label for each pixel based on features\n",
    "'''\n",
    "def createSegmentation(features, k=5):\n",
    "    N,M,d = features.shape\n",
    "    kmeans = # create kmeans module\n",
    "    \n",
    "    # first fit then predict label of each pixel\n",
    "    \n",
    "    return # return segmentation of size N*M x d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part D.\n",
    "\n",
    "Now to do some visualizations! To do this, you will have to write up the whole pipeline that connects each previous part together. We have already written starter code to setup the filterBank and imageStacks from Part A. Now you must do the rest.\n",
    "\n",
    "- (1) Collect the filterResponses from **imageStackGray**.\n",
    "    - Simply call getFilterResponses and pass in imageStackGray and filter bank F.\n",
    "    \n",
    "- (2) Create a textons (Kmeans of responses) module using **createTextons** from data in (1).\n",
    "    - We suggest using the default value of numTextons=50, but this can be experimented with.\n",
    "    \n",
    "Now, **for each image** in imageStack/imageStackGray, do the following (3) to (5) + Visualizations:\n",
    "\n",
    "\n",
    "- (3) Take the current image (**grayscale version**) and extract the histogram features from **part C**.\n",
    "    - You can also experiment with window_size to try and understand how these features change.\n",
    "\n",
    "- (4) Create the segmentation (**part D**) of textonFeatures from (3).\n",
    "    - Feel free to adjust the value of $k$ to test.\n",
    "\n",
    "- (5) In addition, create a **color segmentation** from the original color image.\n",
    "    - This can be done by simply passing in the color version of this image into createSegmentation.\n",
    "    - Feel free to adjust the value of $k$\n",
    "    \n",
    "Now please visualize the following:\n",
    "\n",
    "- The original color image.\n",
    "\n",
    "- Texture Segmentation from (4).\n",
    "    - Make sure to title it with the parameters used (numTextons, window_size and $k$)\n",
    "    \n",
    "- Color Segmentation from (5).\n",
    "    - Make sure to title it with the value of $k$ used.\n",
    "    \n",
    "\n",
    "Useful modules:\n",
    "    - plt.imshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageStack = loadImages(grayscale=False)\n",
    "imageStackGray = loadImages(grayscale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F = loadFilterBank()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = \n",
    "imageGray = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turn in Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have completed Problem 1, please submit (for this part of the assignment):\n",
    "\n",
    "- This .ipynb file.\n",
    "- A PDF version of this file. To do this:\n",
    "    1. Go to File -> Download as -> HTML\n",
    "    2. Open the HTML and Print, and change the **destination** to **PDF**."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
